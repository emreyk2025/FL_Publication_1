{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chosen Data Sets:\n",
    "\n",
    "GoiEner Data Set\n",
    "\n",
    "Smart Grid Smart City Customer Trial Data Set\n",
    "\n",
    "METER UK Household Electricity and Activity Survey, 2016-2019\n",
    "\n",
    "Original SmartMeter dataset (year 2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two versions of this dataset. First is raw data with missing values. The second is where missing values are imputed and the data is segmented in three different periods. pre-, in-, post-pandemic. The number of CSV files, hence customers, are not same in raw and processed data are not same since some of the csv files appear more than once in different periods of pre, in and post pandemic.\n",
    "\n",
    "Here we will first see how many customers have data in different sub periods between 2014 and 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the folder paths for imp_pre, imp_in, and imp_post\n",
    "\n",
    "folder_paths = {\n",
    "    \"pre_pandemic\": \"D:/FL Publication/Datasets for the Publication/GoiEner/7362094/imp-pre/goi4_pre/imp_csv\",\n",
    "    \"in_pandemic\": \"D:/FL Publication/Datasets for the Publication/GoiEner/7362094/imp-in/goi4_in/imp_csv\",\n",
    "    \"post_pandemic\": \"D:/FL Publication/Datasets for the Publication/GoiEner/7362094/imp-post/goi4_pst/imp_csv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store customer IDs for each period\n",
    "# Sets are used to store multiple items in a single variable. These are unordered, unchangeable, and unindexed.\n",
    "customer_ids = {\n",
    "    \"pre_pandemic\": set(),\n",
    "    \"in_pandemic\": set(),\n",
    "    \"post_pandemic\": set()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each folder and read the CSV files\n",
    "for period, folder_path in folder_paths.items():\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".csv\"):\n",
    "            customer_id = file_name.split(\".\")[0]\n",
    "            customer_ids[period].add(customer_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for customers that appear in multiple periods\n",
    "pre_and_in = customer_ids[\"pre_pandemic\"].intersection(customer_ids[\"in_pandemic\"])\n",
    "pre_and_post = customer_ids[\"pre_pandemic\"].intersection(customer_ids[\"post_pandemic\"])\n",
    "in_and_post = customer_ids[\"in_pandemic\"].intersection(customer_ids[\"post_pandemic\"])\n",
    "all_periods = customer_ids[\"pre_pandemic\"].intersection(customer_ids[\"in_pandemic\"], customer_ids[\"post_pandemic\"])\n",
    "\n",
    "results = {\n",
    "    \"pre_and_in_pandemic\": list(pre_and_in),\n",
    "    \"pre_and_post_pandemic\": list(pre_and_post),\n",
    "    \"in_and_post_pandemic\": list(in_and_post),\n",
    "    \"all_periods\": list(all_periods)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     pre_and_in_pandemic  \\\n",
      "0      4ae14bd23af5ea9153c82870a7d46b06042970bdee2c80...   \n",
      "1      897a78edf9694a0a44a7c98fb763d696a5dc2c8503163c...   \n",
      "2      e071ac0732664381e236fb660361d667d467dc7896d42e...   \n",
      "3      193b8e83344d8bea06cb6713a3ac8f706cb9a099fa14cc...   \n",
      "4      832767c8be9103cfd16ede32cf8bc549ce2430bd23e6f2...   \n",
      "...                                                  ...   \n",
      "13905                                                NaN   \n",
      "13906                                                NaN   \n",
      "13907                                                NaN   \n",
      "13908                                                NaN   \n",
      "13909                                                NaN   \n",
      "\n",
      "                                   pre_and_post_pandemic  \\\n",
      "0      4ae14bd23af5ea9153c82870a7d46b06042970bdee2c80...   \n",
      "1      897a78edf9694a0a44a7c98fb763d696a5dc2c8503163c...   \n",
      "2      e071ac0732664381e236fb660361d667d467dc7896d42e...   \n",
      "3      193b8e83344d8bea06cb6713a3ac8f706cb9a099fa14cc...   \n",
      "4      bc4a7956b15ff91d46511c1a6dc43b6aaf72ee9e357d07...   \n",
      "...                                                  ...   \n",
      "13905                                                NaN   \n",
      "13906                                                NaN   \n",
      "13907                                                NaN   \n",
      "13908                                                NaN   \n",
      "13909                                                NaN   \n",
      "\n",
      "                                    in_and_post_pandemic  \\\n",
      "0      4ae14bd23af5ea9153c82870a7d46b06042970bdee2c80...   \n",
      "1      897a78edf9694a0a44a7c98fb763d696a5dc2c8503163c...   \n",
      "2      e071ac0732664381e236fb660361d667d467dc7896d42e...   \n",
      "3      193b8e83344d8bea06cb6713a3ac8f706cb9a099fa14cc...   \n",
      "4      bc4a7956b15ff91d46511c1a6dc43b6aaf72ee9e357d07...   \n",
      "...                                                  ...   \n",
      "13905  251b320a682f3d3d2c2370837b6a2dbc8e8a4f25221265...   \n",
      "13906  d8fa06bd9b097ff19c8dd86dd9b81cec3149983cbcaa02...   \n",
      "13907  8d13e1fa24af45d1cbfc44ddda5f4dda87d095f65bb248...   \n",
      "13908  b761372eddf90053a71390d17217ed1495ea05ede25fcc...   \n",
      "13909  dce5e4b88ada9b574abed3fb1ac410457d42c5cec8fcae...   \n",
      "\n",
      "                                             all_periods  \n",
      "0      4ae14bd23af5ea9153c82870a7d46b06042970bdee2c80...  \n",
      "1      897a78edf9694a0a44a7c98fb763d696a5dc2c8503163c...  \n",
      "2      e071ac0732664381e236fb660361d667d467dc7896d42e...  \n",
      "3      193b8e83344d8bea06cb6713a3ac8f706cb9a099fa14cc...  \n",
      "4      bc4a7956b15ff91d46511c1a6dc43b6aaf72ee9e357d07...  \n",
      "...                                                  ...  \n",
      "13905                                                NaN  \n",
      "13906                                                NaN  \n",
      "13907                                                NaN  \n",
      "13908                                                NaN  \n",
      "13909                                                NaN  \n",
      "\n",
      "[13910 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in results.items()]))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will preprocess csv files one by one and then save them in different folders.\n",
    "\n",
    "preprocessed_folder = \"D:/FL Publication/Datasets for the Publication/GoiEner/7362094/imp_preprocessed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_holidays = holidays.Spain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_holiday(date):\n",
    "    \"\"\"Check if a date is a holiday in Spain.\"\"\"\n",
    "    return date in es_holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will first extract all the possible variables from datetime variable and then look at specific trends for each using graphs\n",
    "\n",
    "# Function to preprocess the data\n",
    "def preprocess_file(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Convert 'timestamp' column to datetime type\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "    # Extract other variables\n",
    "    \n",
    "    df['year'] = df['timestamp'].dt.year.astype('int16')\n",
    "    df['month'] = df['timestamp'].dt.month.astype('int8')\n",
    "    df['day'] = df['timestamp'].dt.day.astype('int16')\n",
    "    df['hour'] = df['timestamp'].dt.hour.astype('int8')\n",
    "    df['day_of_year'] = df['timestamp'].dt.day_of_year.astype('int16')\n",
    "    df['day_of_week'] = df['timestamp'].dt.day_of_week.astype('int8')\n",
    "    df['is_weekend'] = df['timestamp'].dt.dayofweek >= 5\n",
    "    df['is_weekend'] = df['is_weekend'].astype('bool')\n",
    "\n",
    "   # Add holiday information\n",
    "    df['is_holiday'] = df['timestamp'].dt.date.map(is_holiday)\n",
    "    df['is_holiday'] = df['is_holiday'].astype('bool')\n",
    "\n",
    "    # Drop the original timestamp column\n",
    "    df.drop(columns=[\"timestamp\"], inplace=True)\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each file in each folder\n",
    "for period, folder_path in folder_paths.items():\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".csv\"):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            # Preprocess the file\n",
    "            processed_df = preprocess_file(file_path)\n",
    "            # Save to the output folder with the same file name\n",
    "            output_path = os.path.join(preprocessed_folder, period + \"_preprocessed\", file_name)\n",
    "            os.makedirs(os.path.join(preprocessed_folder, period + \"_preprocessed\"), exist_ok=True) \n",
    "            processed_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider including some of the other variables such as economic activity and other metadata to improve prediction (This is in addition to fairness aspect)\n",
    "\n",
    "Remove absolute time, it is unnecessary: Date time already uniquely defines each observation. Also we would like to see how electricity consumption changes in a year, month, week etc with seasonality and date related patterns. Absolute time do not reflect these cyclicalities.\n",
    "\n",
    "Holidays bunu da ekle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "federated_learning_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
